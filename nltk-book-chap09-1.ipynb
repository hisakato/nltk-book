{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Natural Language Processing with Python â€“ Analyzing Text with the Natural Language Toolkit\n",
    "Steven Bird, Ewan Klein, and Edward Loper\n",
    "http://www.nltk.org/book/\n",
    "Chapter 9. Building Feature Based Grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9.1   Grammatical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kim = {'CAT': 'NP', 'ORTH': 'Kim', 'REF': 'k'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chase = {'CAT': 'V', 'ORTH': 'chased', 'REL': 'chase'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chase['AGT'] = 'sbj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chase['PAT'] = 'obj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Kim chased Lee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sent.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lee = {'CAT': 'NP', 'ORTH': 'Lee', 'REF': 'l'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lex2fs(word):\n",
    "    for fs in [kim, lee, chase]:\n",
    "        if fs['ORTH'] == word:\n",
    "            return fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj, verb, obj = lex2fs(tokens[0]), lex2fs(tokens[1]), lex2fs(tokens[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb['AGT'] = subj['REF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb['PAT'] = obj['REF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORTH  => chased\n",
      "REL   => chase\n",
      "AGT   => k\n",
      "PAT   => l\n"
     ]
    }
   ],
   "source": [
    "for k in ['ORTH', 'REL', 'AGT', 'PAT']:\n",
    "    print(\"%-5s => %s\" % (k, verb[k]))\n",
    "# ORTH  => chased\n",
    "# REL   => chase\n",
    "# AGT   => k\n",
    "# PAT   => l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise = {'CAT': 'V', 'ORTH': 'surprised', 'REL': 'surprise',\n",
    "            'SRC': 'sbj', 'EXP': 'obj'}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9.1.1   Syntactic Agreement\n",
    "9.1.2   Using Attributes and Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "# ###################\n",
      "# Grammar Productions\n",
      "# ###################\n",
      "# S expansion productions\n",
      "S -> NP[NUM=?n] VP[NUM=?n]\n",
      "# NP expansion productions\n",
      "NP[NUM=?n] -> N[NUM=?n] \n",
      "NP[NUM=?n] -> PropN[NUM=?n] \n",
      "NP[NUM=?n] -> Det[NUM=?n] N[NUM=?n]\n",
      "NP[NUM=pl] -> N[NUM=pl] \n",
      "# VP expansion productions\n",
      "VP[TENSE=?t, NUM=?n] -> IV[TENSE=?t, NUM=?n]\n",
      "VP[TENSE=?t, NUM=?n] -> TV[TENSE=?t, NUM=?n] NP\n",
      "# ###################\n",
      "# Lexical Productions\n",
      "# ###################\n",
      "Det[NUM=sg] -> 'this' | 'every'\n",
      "Det[NUM=pl] -> 'these' | 'all'\n",
      "Det -> 'the' | 'some' | 'several'\n",
      "PropN[NUM=sg]-> 'Kim' | 'Jody'\n",
      "N[NUM=sg] -> 'dog' | 'girl' | 'car' | 'child'\n",
      "N[NUM=pl] -> 'dogs' | 'girls' | 'cars' | 'children' \n",
      "IV[TENSE=pres,  NUM=sg] -> 'disappears' | 'walks'\n",
      "TV[TENSE=pres, NUM=sg] -> 'sees' | 'likes'\n",
      "IV[TENSE=pres,  NUM=pl] -> 'disappear' | 'walk'\n",
      "TV[TENSE=pres, NUM=pl] -> 'see' | 'like'\n",
      "IV[TENSE=past] -> 'disappeared' | 'walked'\n",
      "TV[TENSE=past] -> 'saw' | 'liked'\n"
     ]
    }
   ],
   "source": [
    "nltk.data.show_cfg('grammars/book_grammars/feat0.fcfg')\n",
    "# % start S\n",
    "# # ###################\n",
    "# # Grammar Productions\n",
    "# # ###################\n",
    "# # S expansion productions\n",
    "# S -> NP[NUM=?n] VP[NUM=?n]\n",
    "# # NP expansion productions\n",
    "# NP[NUM=?n] -> N[NUM=?n]\n",
    "# NP[NUM=?n] -> PropN[NUM=?n]\n",
    "# NP[NUM=?n] -> Det[NUM=?n] N[NUM=?n]\n",
    "# NP[NUM=pl] -> N[NUM=pl]\n",
    "# # VP expansion productions\n",
    "# VP[TENSE=?t, NUM=?n] -> IV[TENSE=?t, NUM=?n]\n",
    "# VP[TENSE=?t, NUM=?n] -> TV[TENSE=?t, NUM=?n] NP\n",
    "# # ###################\n",
    "# # Lexical Productions\n",
    "# # ###################\n",
    "# Det[NUM=sg] -> 'this' | 'every'\n",
    "# Det[NUM=pl] -> 'these' | 'all'\n",
    "# Det -> 'the' | 'some' | 'several'\n",
    "# PropN[NUM=sg]-> 'Kim' | 'Jody'\n",
    "# N[NUM=sg] -> 'dog' | 'girl' | 'car' | 'child'\n",
    "# N[NUM=pl] -> 'dogs' | 'girls' | 'cars' | 'children'\n",
    "# IV[TENSE=pres,  NUM=sg] -> 'disappears' | 'walks'\n",
    "# TV[TENSE=pres, NUM=sg] -> 'sees' | 'likes'\n",
    "# IV[TENSE=pres,  NUM=pl] -> 'disappear' | 'walk'\n",
    "# TV[TENSE=pres, NUM=pl] -> 'see' | 'like'\n",
    "# IV[TENSE=past] -> 'disappeared' | 'walked'\n",
    "# TV[TENSE=past] -> 'saw' | 'liked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = 'Kim likes children'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import load_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = load_parser('grammars/book_grammars/feat0.fcfg', trace=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.Kim .like.chil.|\n",
      "Leaf Init Rule:\n",
      "|[----]    .    .| [0:1] 'Kim'\n",
      "|.    [----]    .| [1:2] 'likes'\n",
      "|.    .    [----]| [2:3] 'children'\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] PropN[NUM='sg'] -> 'Kim' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] NP[NUM='sg'] -> PropN[NUM='sg'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[---->    .    .| [0:1] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'sg'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [----]    .| [1:2] TV[NUM='sg', TENSE='pres'] -> 'likes' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [---->    .| [1:2] VP[NUM=?n, TENSE=?t] -> TV[NUM=?n, TENSE=?t] * NP[] {?n: 'sg', ?t: 'pres'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] N[NUM='pl'] -> 'children' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] NP[NUM='pl'] -> N[NUM='pl'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [---->| [2:3] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'pl'}\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|.    [---------]| [1:3] VP[NUM='sg', TENSE='pres'] -> TV[NUM='sg', TENSE='pres'] NP[] *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|[==============]| [0:3] S[] -> NP[NUM='sg'] VP[NUM='sg'] *\n",
      "(S[]\n",
      "  (NP[NUM='sg'] (PropN[NUM='sg'] Kim))\n",
      "  (VP[NUM='sg', TENSE='pres']\n",
      "    (TV[NUM='sg', TENSE='pres'] likes)\n",
      "    (NP[NUM='pl'] (N[NUM='pl'] children))))\n"
     ]
    }
   ],
   "source": [
    "for tree in cp.parse(tokens):\n",
    "    print(tree)\n",
    "\n",
    "# |.Kim .like.chil.|\n",
    "# Leaf Init Rule:\n",
    "# |[----]    .    .| [0:1] 'Kim'\n",
    "# |.    [----]    .| [1:2] 'likes'\n",
    "# |.    .    [----]| [2:3] 'children'\n",
    "# Feature Bottom Up Predict Combine Rule:\n",
    "# |[----]    .    .| [0:1] PropN[NUM='sg'] -> 'Kim' *\n",
    "# Feature Bottom Up Predict Combine Rule:\n",
    "# |[----]    .    .| [0:1] NP[NUM='sg'] -> PropN[NUM='sg'] *\n",
    "# Feature Bottom Up Predict Combine Rule:\n",
    "# |[---->    .    .| [0:1] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'sg'}\n",
    "# Feature Bottom Up Predict Combine Rule:\n",
    "# |.    [----]    .| [1:2] TV[NUM='sg', TENSE='pres'] -> 'likes' *\n",
    "# Feature Bottom Up Predict Combine Rule:\n",
    "# |.    [---->    .| [1:2] VP[NUM=?n, TENSE=?t] -> TV[NUM=?n, TENSE=?t] * NP[] {?n: 'sg', ?t: 'pres'}\n",
    "# Feature Bottom Up Predict Combine Rule:\n",
    "# |.    .    [----]| [2:3] N[NUM='pl'] -> 'children' *\n",
    "# Feature Bottom Up Predict Combine Rule:\n",
    "# |.    .    [----]| [2:3] NP[NUM='pl'] -> N[NUM='pl'] *\n",
    "# Feature Bottom Up Predict Combine Rule:\n",
    "# |.    .    [---->| [2:3] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'pl'}\n",
    "# Feature Single Edge Fundamental Rule:\n",
    "# |.    [---------]| [1:3] VP[NUM='sg', TENSE='pres'] -> TV[NUM='sg', TENSE='pres'] NP[] *\n",
    "# Feature Single Edge Fundamental Rule:\n",
    "# |[==============]| [0:3] S[] -> NP[NUM='sg'] VP[NUM='sg'] *\n",
    "# (S[]\n",
    "#   (NP[NUM='sg'] (PropN[NUM='sg'] Kim))\n",
    "#   (VP[NUM='sg', TENSE='pres']\n",
    "#     (TV[NUM='sg', TENSE='pres'] likes)\n",
    "#     (NP[NUM='pl'] (N[NUM='pl'] children))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.Kim .like.chil.|\n",
      "Leaf Init Rule:\n",
      "|[----]    .    .| [0:1] 'Kim'\n",
      "|.    [----]    .| [1:2] 'likes'\n",
      "|.    .    [----]| [2:3] 'children'\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] PropN[NUM='sg'] -> 'Kim' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] NP[NUM='sg'] -> PropN[NUM='sg'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[---->    .    .| [0:1] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'sg'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [----]    .| [1:2] TV[NUM='sg', TENSE='pres'] -> 'likes' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [---->    .| [1:2] VP[NUM=?n, TENSE=?t] -> TV[NUM=?n, TENSE=?t] * NP[] {?n: 'sg', ?t: 'pres'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] N[NUM='pl'] -> 'children' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] NP[NUM='pl'] -> N[NUM='pl'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [---->| [2:3] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'pl'}\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|.    [---------]| [1:3] VP[NUM='sg', TENSE='pres'] -> TV[NUM='sg', TENSE='pres'] NP[] *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|[==============]| [0:3] S[] -> NP[NUM='sg'] VP[NUM='sg'] *\n",
      "(S[]\n",
      "  (NP[NUM='sg'] (PropN[NUM='sg'] Kim))\n",
      "  (VP[NUM='sg', TENSE='pres']\n",
      "    (TV[NUM='sg', TENSE='pres'] likes)\n",
      "    (NP[NUM='pl'] (N[NUM='pl'] children))))\n"
     ]
    }
   ],
   "source": [
    "# trees = cp.parse(tokens)\n",
    "for tree in trees: print(tree)\n",
    "# (S[]\n",
    "#   (NP[NUM='sg'] (PropN[NUM='sg'] Kim))\n",
    "#   (VP[NUM='sg', TENSE='pres']\n",
    "#     (TV[NUM='sg', TENSE='pres'] likes)\n",
    "#     (NP[NUM='pl'] (N[NUM='pl'] children))))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9.1.3   Terminology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
